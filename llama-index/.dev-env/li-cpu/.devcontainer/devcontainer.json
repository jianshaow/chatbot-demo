{
	"name": "LI-CPU",
	"image": "jianshao/llamaindex-demo:0.0.9-cpu",
	"remoteEnv": {
		"PYTHONPATH": ".",
		"HF_MODEL": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
		"LLAMA_INDEX_CACHE_DIR": "/home/devel/.cache/huggingface/hub"
	},
	"runArgs": [
		"--add-host=host.docker.internal:host-gateway"
	],
	"mounts": [
		{
			"source": "${localEnv:HOME}/.config",
			"target": "/home/devel/.config",
			"type": "bind"
		},
		{
			"source": "${localEnv:HOME}/.cache",
			"target": "/home/devel/.cache",
			"type": "bind"
		},
		{
			"source": "${localEnv:HOME}/.ssh",
			"target": "/home/devel/.ssh",
			"type": "bind"
		}
	],
	"customizations": {
		"vscode": {
			"extensions": [
				"ms-python.python",
				"ms-python.vscode-pylance",
				"ms-python.black-formatter",
				"ms-python.isort",
				"alphabotsec.vscode-eclipse-keybindings"
			]
		}
	}
}
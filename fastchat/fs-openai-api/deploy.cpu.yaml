apiVersion: apps/v1
kind: Deployment
metadata:
  name: fc-openai-api
  namespace: demo
spec:
  selector:
    matchLabels:
      app: fc-openai-api
  replicas: 1
  template:
    metadata:
      labels:
        app: fc-openai-api
    spec:
      restartPolicy: Always
      containers:
      - name: controller
        image: jianshao/fastchat-demo:0.0.4
        ports:
        - containerPort: 21001
        command:
        - python
        - -m
        - fastchat.serve.controller
        - --host
        - 0.0.0.0
      - name: embedding-worker
        image: jianshao/fastchat-demo:0.0.4
        envFrom:
        - configMapRef:
            name: openai-env-cm
        ports:
        - containerPort: 21002
        command:
        - python
        - -m
        - fastchat.serve.model_worker
        - --host
        - 0.0.0.0
        - --worker-address
        - http://localhost:21002
        - --model-names
        - text-embedding-ada-002
        - --model-path
        - $(embedding_model_path)
        - --device
        - cpu
        volumeMounts:
        - mountPath: /home/devel/.cache
          name: model-cache-dir
      - name: chat-worker
        image: jianshao/fastchat-demo:0.0.4
        envFrom:
        - configMapRef:
            name: openai-env-cm
        ports:
        - containerPort: 21003
        command:
        - python
        - -m
        - fastchat.serve.model_worker
        - --host
        - 0.0.0.0
        - --port
        - '21003'
        - --worker-address
        - http://localhost:21003
        - --model-names
        - gpt-3.5-turbo
        - --model-path
        - $(chat_model_path)
        - --device
        - cpu
        volumeMounts:
        - mountPath: /home/devel/.cache
          name: model-cache-dir
      - name: openai
        image: jianshao/fastchat-demo:0.0.4
        ports:
        - containerPort: 8000
        command:
        - python
        - -m
        - fastchat.serve.openai_api_server
        - --host
        - 0.0.0.0
      - name: nextchat
        image: yidadaa/chatgpt-next-web:v2.11.3
        env:
        - name: BASE_URL
          value: http://localhost:8000
        ports:
        - containerPort: 3000
      volumes:
      - name: model-cache-dir
        persistentVolumeClaim:
          claimName: model-cache-dir-pvc

version: "3"
services:
  openai:
    image: jianshao/ollama-server:${image_ver}
    container_name: ${container_name_prefix}openai
    restart: unless-stopped
    environment:
      - https_proxy=${https_proxy}
    volumes:
      - ${model_cache_path}:/home/devel/.ollama
    ports:
      - 8000:11434
  webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ${container_name_prefix}webui
    restart: unless-stopped
    depends_on:
      - openai
    environment:
      - OLLAMA_BASE_URL=http://openai:11434
    ports:
      - 3000:8080
